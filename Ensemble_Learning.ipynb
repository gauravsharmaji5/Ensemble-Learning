{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is Ensemble Learning in machine learning? Explain the key idea behind it.\n",
        "Ans.1 : Ensemble Learning in machine learning is a technique where multiple models (called base learners or weak learners) are combined to solve the same problem in order to achieve better performance than any single model alone.\n",
        "\n",
        "üîë Key Idea Behind Ensemble Learning\n",
        "\n",
        "‚ÄúThe wisdom of the crowd is better than the opinion of an individual.‚Äù\n",
        "\n",
        "Instead of relying on one model (which might make mistakes due to bias, variance, or noise), we train several models and combine their predictions.\n",
        "\n",
        "The errors of individual models tend to cancel out when aggregated, leading to higher accuracy, robustness, and generalization.\n",
        "\n",
        "Types of Ensemble Learning\n",
        "\n",
        "Bagging (Bootstrap Aggregating)\n",
        "\n",
        "Trains multiple models in parallel on different subsets of the training data (sampled with replacement).\n",
        "\n",
        "Final prediction is made by averaging (regression) or voting (classification).\n",
        "\n",
        "Example: Random Forest.\n",
        "\n",
        "Boosting\n",
        "\n",
        "Models are trained sequentially, each new model focusing on the mistakes of the previous ones.\n",
        "\n",
        "Predictions are combined through weighted voting.\n",
        "\n",
        "Example: AdaBoost, Gradient Boosting, XGBoost, LightGBM.\n",
        "\n",
        "Stacking\n",
        "\n",
        "Combines different types of models (e.g., decision trees, logistic regression, neural nets).\n",
        "\n",
        "A meta-model learns how to best combine their predictions.\n",
        "\n",
        "Why Use Ensemble Learning?\n",
        "\n",
        "‚úÖ Reduces overfitting (especially bagging)\n",
        "‚úÖ Reduces bias (especially boosting)\n",
        "‚úÖ Handles complex datasets better\n",
        "‚úÖ Improves accuracy and stability"
      ],
      "metadata": {
        "id": "RIwcY7Gy6ZPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the difference between Bagging and Boosting?\n",
        "Ans.2: üîë Difference Between Bagging and Boosting\n",
        "Aspect\tBagging (Bootstrap Aggregating)\tBoosting\n",
        "Main Goal\tReduce variance (overfitting)\tReduce bias (underfitting)\n",
        "How Models Are Built\tTrains multiple models independently in parallel\tTrains models sequentially (each new model corrects previous mistakes)\n",
        "Data Sampling\tEach model gets a random sample (with replacement) from the training data\tUses the entire dataset, but weights are adjusted to focus more on hard-to-predict examples\n",
        "Model Importance\tAll models have equal weight in final prediction\tLater models have higher weight (more importance)\n",
        "Combination Method\tMajority voting (classification) or averaging (regression)\tWeighted voting/weighted average\n",
        "Risk of Overfitting\tLess prone to overfitting\tMore prone to overfitting (but can achieve very high accuracy)\n",
        "Examples\tRandom Forest\tAdaBoost, Gradient Boosting, XGBoost, LightGBM\n",
        "üìå Intuition with Example:\n",
        "\n",
        "Imagine you want to predict whether a student will pass an exam.\n",
        "\n",
        "Bagging (Random Forest):\n",
        "\n",
        "You ask 100 different teachers, each looking at a different random subset of past exam papers.\n",
        "\n",
        "Each teacher votes PASS or FAIL, and you go with the majority vote.\n",
        "\n",
        "Helps reduce noise from any single teacher‚Äôs opinion.\n",
        "\n",
        "Boosting (AdaBoost, XGBoost):\n",
        "\n",
        "You ask teachers one by one.\n",
        "\n",
        "The first teacher may misjudge some students.\n",
        "\n",
        "The second teacher focuses more on those students that the first one got wrong.\n",
        "\n",
        "Over time, the group becomes better at predicting by focusing on the mistakes."
      ],
      "metadata": {
        "id": "DmcrJF8c6nrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?\n",
        "Ans.3: What is Bootstrap Sampling?\n",
        "\n",
        "Bootstrap sampling is a statistical technique where we create new datasets by randomly sampling from the original dataset with replacement.\n",
        "\n",
        "Each bootstrap sample has the same size as the original dataset, but because of replacement:\n",
        "\n",
        "Some observations appear multiple times.\n",
        "\n",
        "Some observations may not appear at all.\n",
        "\n",
        "üëâ For a dataset of size N, on average each bootstrap sample contains about 63% unique observations (the rest are repeats).\n",
        "\n",
        "üîë Role of Bootstrap Sampling in Bagging\n",
        "\n",
        "Bagging = Bootstrap Aggregating ‚Üí the name itself comes from bootstrap sampling.\n",
        "\n",
        "Here‚Äôs how it works in methods like Random Forest:\n",
        "\n",
        "From the original dataset, generate multiple bootstrap samples.\n",
        "Example: If we create 100 decision trees, we generate 100 bootstrap samples.\n",
        "\n",
        "Train a separate model (e.g., decision tree) on each bootstrap sample.\n",
        "\n",
        "Combine predictions:\n",
        "\n",
        "For classification ‚Üí majority vote.\n",
        "\n",
        "For regression ‚Üí average prediction.\n",
        "\n",
        "üìå Why Use Bootstrap Sampling?\n",
        "\n",
        "Diversity of Models:\n",
        "\n",
        "Each model sees a slightly different dataset, so it makes different errors.\n",
        "\n",
        "This diversity reduces variance and prevents overfitting.\n",
        "\n",
        "Stability of Prediction:\n",
        "\n",
        "Individual decision trees are very unstable (high variance).\n",
        "\n",
        "By averaging many trees trained on different bootstrap samples, the Random Forest becomes much more stable and accurate.\n",
        "\n",
        "Out-of-Bag (OOB) Error Estimate:\n",
        "\n",
        "Since ~37% of the data is not included in each bootstrap sample, it can be used as a test set for that tree.\n",
        "\n",
        "This allows Random Forests to internally estimate their test error without needing a separate validation set."
      ],
      "metadata": {
        "id": "sPY8excU61r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?\n",
        "Ans.4: What are Out-of-Bag (OOB) Samples?\n",
        "\n",
        "In Bagging/Random Forests, each tree is trained on a bootstrap sample of the dataset.\n",
        "\n",
        "On average, each bootstrap sample contains about 63% of the original data (with duplicates).\n",
        "\n",
        "The remaining ~37% of the data not included in that sample are called the Out-of-Bag (OOB) samples for that tree.\n",
        "\n",
        "üëâ So for every tree, we automatically have a small \"test set\" (the OOB samples).\n",
        "\n",
        "üîë How is OOB Score Used?\n",
        "\n",
        "The OOB score is an internal estimate of model accuracy without using a separate validation/test set.\n",
        "\n",
        "Here‚Äôs how it works in Random Forests:\n",
        "\n",
        "For each data point in the dataset:\n",
        "\n",
        "It is likely to be out-of-bag for some subset of trees.\n",
        "\n",
        "Those trees did not see this point during training.\n",
        "\n",
        "To predict that data point:\n",
        "\n",
        "Take the predictions only from the trees where the point was OOB.\n",
        "\n",
        "Combine them (majority vote for classification, average for regression).\n",
        "\n",
        "Compare the aggregated OOB prediction with the actual label.\n",
        "\n",
        "Repeat for all data points ‚Üí compute the OOB error rate (1 ‚àí OOB score).\n",
        "\n",
        "üìå Advantages of OOB Score\n",
        "\n",
        "‚úÖ Acts as a built-in cross-validation ‚Üí no need for a separate validation dataset.\n",
        "‚úÖ Gives an unbiased estimate of generalization error.\n",
        "‚úÖ Saves computation and data (important for small datasets).\n",
        "\n",
        "üîé Example Intuition\n",
        "\n",
        "Suppose we train a Random Forest with 100 trees:\n",
        "\n",
        "Data point X is out-of-bag in 40 of them.\n",
        "\n",
        "We predict X using those 40 trees ‚Üí final OOB prediction = majority vote.\n",
        "\n",
        "If OOB predictions match true labels 90% of the time, then OOB score = 0.90."
      ],
      "metadata": {
        "id": "XLsFrxEq7F2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Compare feature importance analysis in a single Decision Tree vs. a Random Forest?\n",
        "Ans.5: üå≥ Feature Importance in Decision Tree\n",
        "\n",
        "In a single decision tree, feature importance is computed based on how much a feature helps in reducing impurity (e.g., Gini Index, Entropy, or MSE) when it is used to split the data.\n",
        "\n",
        "At each split:\n",
        "\n",
        "Calculate impurity reduction.\n",
        "\n",
        "Assign this reduction to the feature used.\n",
        "\n",
        "At the end:\n",
        "\n",
        "Importance of each feature = sum of all impurity reductions across nodes where it was used, normalized so that the total importance = 1.\n",
        "\n",
        "‚úÖ Pros:\n",
        "\n",
        "Easy to interpret.\n",
        "\n",
        "Shows which feature the tree relied on most.\n",
        "\n",
        "‚ùå Cons:\n",
        "\n",
        "Can be biased if one feature has many possible split points (e.g., continuous variables vs categorical with few levels).\n",
        "\n",
        "Only reflects importance for that single tree ‚Üí can be unstable (a small change in data can lead to a different tree).\n",
        "\n",
        "üå≤ Feature Importance in Random Forest\n",
        "\n",
        "A Random Forest consists of many decision trees trained on bootstrap samples with feature randomness.\n",
        "\n",
        "Feature importance is averaged across all trees. Two common approaches:\n",
        "\n",
        "Mean Decrease in Impurity (MDI)\n",
        "\n",
        "Similar to single tree ‚Üí each tree gives impurity reductions per feature.\n",
        "\n",
        "Then averaged across all trees.\n",
        "\n",
        "More stable and less biased than a single tree, but still can favor continuous variables or high-cardinality categorical features.\n",
        "\n",
        "Mean Decrease in Accuracy (MDA) (a.k.a. Permutation Importance)\n",
        "\n",
        "Randomly shuffle values of a feature in the OOB samples.\n",
        "\n",
        "Measure drop in prediction accuracy.\n",
        "\n",
        "Larger drop = higher importance.\n",
        "\n",
        "Less biased, captures true predictive power.\n",
        "\n",
        "‚úÖ Pros:\n",
        "\n",
        "Much more robust and stable than a single tree.\n",
        "\n",
        "Captures feature importance across many different perspectives of the data.\n",
        "\n",
        "‚ùå Cons:\n",
        "\n",
        "Harder to interpret than a single tree.\n",
        "\n",
        "Permutation importance can be computationally expensive.\n",
        "\n",
        "üìä Comparison Summary\n",
        "Aspect\tDecision Tree\tRandom Forest\n",
        "Stability\tUnstable, can change with small data variation\tStable (averages across many trees)\n",
        "Bias\tBiased towards continuous/many-split features\tReduced bias (but MDI still has some bias)\n",
        "Interpretability\tVery easy to interpret\tHarder (aggregate effect of many trees)\n",
        "Accuracy of Importance\tLess reliable\tMore reliable (especially with permutation importance)"
      ],
      "metadata": {
        "id": "hHyUilPp7ZYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 6: Write a Python program to:\n",
        "‚óè Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "‚óè Train a Random Forest Classifier\n",
        "‚óè Print the top 5 most important features based on feature importance scores.'''\n",
        "'''Ans.6'''\n",
        "# Import required libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importance scores\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort by importance and display top 5\n",
        "top5 = feature_importances.sort_values(by='Importance', ascending=False).head(5)\n",
        "print(\"Top 5 Most Important Features in Breast Cancer Classification:\")\n",
        "print(top5.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--5JAZIS7pwX",
        "outputId": "0a9bce11-e76e-4854-cdb7-dc466b06ea98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features in Breast Cancer Classification:\n",
            "             Feature  Importance\n",
            "          worst area    0.139357\n",
            "worst concave points    0.132225\n",
            " mean concave points    0.107046\n",
            "        worst radius    0.082848\n",
            "     worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import AnyStr\n",
        "'''Question 7: Write a Python program to:\n",
        "‚óè Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "‚óè Evaluate its accuracy and compare with a single Decision Tree '''\n",
        "'''Ans'''\n",
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train a single Decision Tree classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Train a Bagging Classifier using Decision Trees as base estimators\n",
        "bagging_model = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "bagging_model.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Print the accuracy comparison\n",
        "print(\"Accuracy of Single Decision Tree: {:.4f}\".format(accuracy_dt))\n",
        "print(\"Accuracy of Bagging Classifier:   {:.4f}\".format(accuracy_bagging))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "5CvzrdCu7-Lz",
        "outputId": "49b0324c-dc8d-4bf5-c8a7-01c63d12c59a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1790427773.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Train a Bagging Classifier using Decision Trees as base estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m bagging_model = BaggingClassifier(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.8  Write a Python program to:\n",
        "‚óè Train a Random Forest Classifier\n",
        "‚óè Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "‚óè Print the best parameters and final accuracy '''\n",
        "'''Ans.8'''\n",
        "# Import libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (Breast Cancer dataset for example)\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],   # number of trees\n",
        "    'max_depth': [None, 5, 10, 20]    # maximum depth of trees\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,             # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Final Accuracy on Test Set: {:.4f}\".format(final_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGMGcXW9SdM",
        "outputId": "8a8ecc0b-fdc5-4a58-8950-85df895a35bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 100}\n",
            "Final Accuracy on Test Set: 0.9357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 9: Write a Python program to:\n",
        "‚óè Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset\n",
        "‚óè Compare their Mean Squared Errors (MSE) '''\n",
        "'''Ans'''\n",
        "# Import libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Bagging Regressor with Decision Trees\n",
        "bagging = BaggingRegressor(\n",
        "    base_estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging.predict(X_test)\n",
        "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# Print results\n",
        "print(\"Mean Squared Error (Bagging Regressor): {:.4f}\".format(mse_bagging))\n",
        "print(\"Mean Squared Error (Random Forest Regressor): {:.4f}\".format(mse_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "iGsC5xN79nWI",
        "outputId": "afab4aef-0662-4545-874f-e5cc3551fe7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "BaggingRegressor.__init__() got an unexpected keyword argument 'base_estimator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2834445746.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Train Bagging Regressor with Decision Trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m bagging = BaggingRegressor(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BaggingRegressor.__init__() got an unexpected keyword argument 'base_estimator'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.\n",
        "You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "‚óè Choose between Bagging or Boosting\n",
        "‚óè Handle overfitting\n",
        "‚óè Select base models\n",
        "‚óè Evaluate performance using cross-validation\n",
        "‚óè Justify how ensemble learning improves decision-making in this real-world\n",
        "context.\n",
        "Ans. 1) Choose between Bagging vs Boosting\n",
        "\n",
        "Start with both, keep the one that wins on out-of-time (OOT) data and governance needs. Practical guidance:\n",
        "\n",
        "Boosting (XGBoost / LightGBM / CatBoost)\n",
        "\n",
        "Best for tabular data with complex, non-linear interactions.\n",
        "\n",
        "Typically higher AUC/KS than bagging given proper regularization.\n",
        "\n",
        "Handles missing values and mixed feature types well.\n",
        "\n",
        "Pick when you can manage regularization/early stopping and need top accuracy.\n",
        "\n",
        "Bagging (Random Forest)\n",
        "\n",
        "Extremely robust, low tuning burden, strong baseline.\n",
        "\n",
        "Prefer if features are noisy, you need stability/variance reduction, or simpler governance.\n",
        "\n",
        "Great as a level-0 model in stacking for diversity.\n",
        "\n",
        "Recommendation: Build a Random Forest baseline for a sanity check and a regularized gradient boosting model as a contender. If governance demands simpler behavior, keep RF; otherwise expect boosting to win.\n",
        "\n",
        "2) Handle Overfitting (data + model)\n",
        "\n",
        "Data leakage is the #1 risk in finance. Enforce these first:\n",
        "\n",
        "Temporal splits: Create features from a pre-loan observation window (e.g., last 6‚Äì12 months) and predict default in a future performance window (e.g., 90/180 days after origination). Use time-based CV and OOT validation.\n",
        "\n",
        "Aggregation discipline: Build transaction features with rolling windows ending before the label date (e.g., mean/median/volatility of balances, delinquency counts, income inflow stability, merchant category shares, max utilization).\n",
        "\n",
        "Imbalance handling: Prefer class weights or sample weights over oversampling; consider focal loss (boosting) if supported.\n",
        "\n",
        "Model-level controls\n",
        "\n",
        "Random Forest: Limit max_depth, tune max_features, use many trees; check OOB error as a quick guardrail.\n",
        "\n",
        "Boosting: Use shallow trees (depth 3‚Äì8), low learning rate, subsample/colsample_bytree, L2/L1 regularization, and early stopping on a time-consistent validation set.\n",
        "\n",
        "Monotonic constraints (when domain knowledge applies): e.g., higher DTI should not reduce PD; improves generalization and auditability.\n",
        "\n",
        "Feature pruning: Remove unstable/leaky features (e.g., those requiring future info); drop redundant, highly collinear engineered stats if they add variance.\n",
        "\n",
        "3) Select Base Models\n",
        "\n",
        "Baseline: Regularized Logistic Regression (strongly interpretable; gives calibrated PDs after Platt/Isotonic scaling).\n",
        "\n",
        "Tree-based ensembles:\n",
        "\n",
        "Random Forest (bagging) for robustness.\n",
        "\n",
        "LightGBM / XGBoost / CatBoost (boosting) for performance (CatBoost shines with high-cardinality categoricals).\n",
        "\n",
        "Stacking (optional for a final push): Combine LogReg, RF, and GBM; meta-learner = Logistic Regression on out-of-fold predictions to keep things auditable. Ensure clean OOF generation to avoid leakage.\n",
        "\n",
        "4) Evaluate with Cross-Validation (finance-aware)\n",
        "\n",
        "Split strategy: Time-series CV (rolling/forward chaining) + a held-out OOT period that mimics deployment conditions (e.g., most recent quarter). Avoid random K-folds; they inflate scores.\n",
        "\n",
        "Stratification: Maintain class ratio per fold; apply sample weights if class- or segment-imbalance exists.\n",
        "\n",
        "Primary metrics:\n",
        "\n",
        "ROC-AUC and PR-AUC (imbalance-aware).\n",
        "\n",
        "KS statistic (standard in credit risk).\n",
        "\n",
        "Brier score + Calibration curves (we need well-calibrated PDs).\n",
        "\n",
        "Business metrics:\n",
        "\n",
        "Lift/decile analysis (top decile capture rate).\n",
        "\n",
        "Cost/benefit at chosen cutoffs (expected loss).\n",
        "\n",
        "Stability: PSI over time, score drift, and variance across folds.\n",
        "\n",
        "Hyperparameter tuning: Nested CV or time-aware train/valid splits; early stopping for boosting; compare to RF OOB as a quick baseline.\n",
        "\n",
        "5) Decision Thresholds, Calibration, and Governance\n",
        "\n",
        "Calibration: Post-train isotonic or Platt calibration (on a clean validation slice) so outputs are bona-fide PDs.\n",
        "\n",
        "Thresholding by economics: Choose approval cutoff\n",
        "ùëê\n",
        "c that maximizes expected profit or minimizes expected loss:\n",
        "\n",
        "EL\n",
        "=\n",
        "PD\n",
        "√ó\n",
        "LGD\n",
        "√ó\n",
        "EAD\n",
        "EL=PD√óLGD√óEAD\n",
        "\n",
        "Use portfolio constraints (capital, approval rate, segment limits).\n",
        "\n",
        "Fairness & compliance: Monitor subgroup performance (AUC/KS, calibration, error rates) across protected classes; document features, constraints, and reason codes.\n",
        "\n",
        "Explainability: Use SHAP for global/local explanations, feature monotonicity, and reason codes for adverse action notices.\n",
        "\n",
        "6) Why ensemble learning improves real-world decisions here\n",
        "\n",
        "Higher discrimination: Boosting typically yields better rank-ordering (higher AUC/KS), concentrating risk in top deciles ‚Üí targeted declines or pricing.\n",
        "\n",
        "Robustness: Bagging reduces variance; predictions are more stable across time and noise ‚Üí fewer unpleasant surprises in new vintages.\n",
        "\n",
        "Calibrated PDs ‚Üí better economics: With good calibration, you can set risk-based pricing, credit limits, and collections strategies using EL = PD√óLGD√óEAD instead of blunt cutoffs.\n",
        "\n",
        "Operational lift: Decile/lift gains translate into fewer defaults at the same approval rate or higher approvals at constant risk, directly impacting NIM & charge-offs.\n",
        "\n",
        "Governance-friendly stacking: Combining diverse learners smooths idiosyncrasies of any single model while retaining interpretability via SHAP + monotone constraints.\n",
        "\n",
        "Minimal workout plan you can implement now\n",
        "\n",
        "Build RF baseline (OOB + time OOT).\n",
        "\n",
        "Train LightGBM with shallow trees, subsampling, early stopping; apply isotonic calibration.\n",
        "\n",
        "Compare on time-series CV + OOT using AUC/PR-AUC/KS, Brier, calibration plots, and decile lift.\n",
        "\n",
        "If needed, stack (LogReg + RF + GBM ‚Üí meta-LogReg using OOF preds).\n",
        "\n",
        "Select threshold by expected profit/loss and validate fairness/stability.\n",
        "\n",
        "Package with monitoring: drift (PSI), calibration, population stability, periodic OOT checks."
      ],
      "metadata": {
        "id": "IKM3c5YV-bqN"
      }
    }
  ]
}